FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /root
COPY torchserve/clone-torchserve.sh /torchserve/clone-torchserve.sh
COPY torchserve/install-common.sh /torchserve/install-common.sh
COPY torchserve/install-torchserve.sh /torchserve/install-torchserve.sh
RUN --mount=type=cache,target=/root/.cache /torchserve/install-torchserve.sh --cuda cu118
RUN /usr/local/bin/torchserve --help
COPY torchserve/config.properties /torchserve/config.properties
COPY torchserve/torchserve-entrypoint.sh /torchserve/torchserve-entrypoint.sh
COPY torchserve/healthcheck.sh /torchserve/healthcheck.sh
HEALTHCHECK CMD /torchserve/healthcheck.sh || exit 1
ENTRYPOINT ["/torchserve/torchserve-entrypoint.sh"]

# see Dockerfile.torchserve for example, but use
# docker run --gpus all -ti iqtlabs/cuda-torchserve:latest bash
# ensure nvidia-container-toolkit is installed (https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
# CUDA version on the host must be same or later, than that in this container.
