FROM rocm/pytorch:latest
ARG PIP_CACHE
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /root
COPY torchserve/pipcacheconfig.sh /torchserve/pipcacheconfig.sh
COPY torchserve/clone-torchserve.sh /torchserve/clone-torchserve.sh
COPY torchserve/install-common.sh /torchserve/install-common.sh
COPY torchserve/install-rocm-torchserve.sh /torchserve/install-rocm-torchserve.sh
RUN /torchserve/pipcacheconfig.sh
RUN --mount=type=cache,target=/root/.cache /torchserve/install-rocm-torchserve.sh
RUN torchserve --help
COPY torchserve/config.properties /torchserve/config.properties
COPY torchserve/torchserve-rocm-entrypoint.sh /torchserve/torchserve-entrypoint.sh
COPY torchserve/healthcheck.sh /torchserve/healthcheck.sh
HEALTHCHECK CMD /torchserve/healthcheck.sh || exit 1
ENTRYPOINT ["/torchserve/torchserve-entrypoint.sh"]

# TODO: must build locally - 20+GB required, which is too much for Github.
# From https://rocm.docs.amd.com/en/latest/how_to/pytorch_install/pytorch_install.html
# docker run command, should return True if ROCm is available.
#
# $ git clone https://github.com/iqtlabs/torchserve
# $ cd torchserve
# $ docker build -f docker/Dockerfile.rocm-torchserve . -t iqtlabs/rocm-torchserve
# $ docker run --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --device=/dev/kfd --device=/dev/dri --group-add video --ipc=host --shm-size 8G --entrypoint python3 -ti iqtlabs/rocm-torchserve -c "import torch ; print(torch.cuda.is_available())"
